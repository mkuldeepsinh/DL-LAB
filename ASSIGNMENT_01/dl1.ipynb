{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqc3FYiKZ57o",
        "outputId": "d09057e7-4c63-4bca-9387-9843ffbf6744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t1: tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "t2: tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "t3: tensor([[-0.2422,  0.2289],\n",
            "        [-0.0603,  1.0391]])\n",
            "Addition Result (t1 + t2):\n",
            "tensor([[2., 3.],\n",
            "        [4., 5.]])\n",
            "Multiplication Result (t1 * 5):\n",
            "tensor([[ 5., 10.],\n",
            "        [15., 20.]])\n",
            "Subtraction Result (t1 - t3):\n",
            "tensor([[1.2422, 1.7711],\n",
            "        [3.0603, 2.9609]])\n",
            "Indexing Result (t1[:, 1]): tensor([2., 4.])\n",
            "Reshaped Tensor (t1.view(4)): tensor([1., 2., 3., 4.])\n",
            "Gradient (x.grad): tensor([9.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "t1 = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32)\n",
        "t2 = torch.ones((2, 2))\n",
        "t3 = torch.randn(2, 2)\n",
        "\n",
        "print(\"t1:\", t1)\n",
        "print(\"t2:\", t2)\n",
        "print(\"t3:\", t3)\n",
        "\n",
        "add_res = t1 + t2\n",
        "mul_res = t1 * 5\n",
        "sub_res = t1 - t3\n",
        "idx_res = t1[:, 1]\n",
        "reshaped = t1.view(4)\n",
        "\n",
        "print(\"Addition Result (t1 + t2):\")\n",
        "print(add_res)\n",
        "print(\"Multiplication Result (t1 * 5):\")\n",
        "print(mul_res)\n",
        "print(\"Subtraction Result (t1 - t3):\")\n",
        "print(sub_res)\n",
        "print(\"Indexing Result (t1[:, 1]):\", idx_res)\n",
        "print(\"Reshaped Tensor (t1.view(4)):\", reshaped)\n",
        "\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "y = x**2 + 5*x\n",
        "y.backward()\n",
        "grad_val = x.grad\n",
        "\n",
        "print(\"Gradient (x.grad):\", grad_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnRpGm2GbjvB",
        "outputId": "26d3065e-78d6-4b19-e667-089aced14ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            "[[1. 2.]\n",
            " [3. 4.]]\n",
            "Matrix B:\n",
            "[[5. 6.]\n",
            " [7. 8.]]\n",
            "Addition (mat_a + mat_b):\n",
            "[[ 6.  8.]\n",
            " [10. 12.]]\n",
            "Matrix Multiplication (mat_a @ mat_b):\n",
            "[[19. 22.]\n",
            " [43. 50.]]\n",
            "Transpose of mat_a:\n",
            "[[1. 3.]\n",
            " [2. 4.]]\n",
            "Determinant of mat_a: -2.0\n",
            "Inverse of mat_a:\n",
            "[[-2.0000002   1.0000001 ]\n",
            " [ 1.5000001  -0.50000006]]\n",
            "Eigenvalues of mat_a: [-0.8541021  5.854102 ]\n",
            "Eigenvectors of mat_a:\n",
            "[[-0.85065085 -0.5257311 ]\n",
            " [ 0.5257311  -0.85065085]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mat_a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "mat_b = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
        "\n",
        "print(\"Matrix A:\")\n",
        "print(mat_a.numpy())\n",
        "print(\"Matrix B:\")\n",
        "print(mat_b.numpy())\n",
        "\n",
        "add_tf = tf.add(mat_a, mat_b)\n",
        "matmul_tf = tf.matmul(mat_a, mat_b)\n",
        "transpose_tf = tf.transpose(mat_a)\n",
        "det_tf = tf.linalg.det(mat_a)\n",
        "inv_tf = tf.linalg.inv(mat_a)\n",
        "eig_vals, eig_vecs = tf.linalg.eigh(mat_a)\n",
        "\n",
        "print(\"Addition (mat_a + mat_b):\")\n",
        "print(add_tf.numpy())\n",
        "print(\"Matrix Multiplication (mat_a @ mat_b):\")\n",
        "print(matmul_tf.numpy())\n",
        "print(\"Transpose of mat_a:\")\n",
        "print(transpose_tf.numpy())\n",
        "print(\"Determinant of mat_a:\", det_tf.numpy())\n",
        "print(\"Inverse of mat_a:\")\n",
        "print(inv_tf.numpy())\n",
        "print(\"Eigenvalues of mat_a:\", eig_vals.numpy())\n",
        "print(\"Eigenvectors of mat_a:\")\n",
        "print(eig_vecs.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBJb4li6i6LA",
        "outputId": "775f06ac-2e94-427e-8d75-fcdc534cccb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AND Gate Results: [0, 0, 0, 1]\n",
            "OR Gate Results: [0, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def perceptron(inputs, weights, bias):\n",
        "    activation = np.dot(inputs, weights) + bias\n",
        "    return 1 if activation >= 0 else 0\n",
        "\n",
        "def solve_gate(gate_type):\n",
        "    inputs = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "    if gate_type == \"AND\":\n",
        "        w, b = np.array([1, 1]), -1.5\n",
        "    elif gate_type == \"OR\":\n",
        "        w, b = np.array([1, 1]), -0.5\n",
        "    else:\n",
        "        return \"Unsupported gate type\"\n",
        "\n",
        "    return [perceptron(i, w, b) for i in inputs]\n",
        "\n",
        "and_results = solve_gate(\"AND\")\n",
        "or_results = solve_gate(\"OR\")\n",
        "\n",
        "print(\"AND Gate Results:\", and_results)\n",
        "print(\"OR Gate Results:\", or_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vwP0istYoD-",
        "outputId": "3a48448c-10db-473c-e27a-539ff531dd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Loss after training: 0.0016351693775504827\n",
            "Final predictions on input X:\n",
            "[[1.1125613e-04]\n",
            " [9.9952531e-01]\n",
            " [9.9752003e-01]\n",
            " [3.4452819e-03]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "X = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float32)\n",
        "Y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "model_xor = nn.Sequential(\n",
        "    nn.Linear(2, 4),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(4, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model_xor.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_xor(X)\n",
        "    loss = criterion(outputs, Y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Final Loss after training:\", loss.item())\n",
        "outputs_final = model_xor(X)\n",
        "print(\"Final predictions on input X:\")\n",
        "print(outputs_final.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWxYze_rYsuP",
        "outputId": "64c14b51-f9de-42ef-b7fe-9c5251e1506b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction for dummy input: -0.017223209142684937\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RegressionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionNN, self).__init__()\n",
        "        self.hidden = nn.Linear(2, 2)\n",
        "        self.output = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.hidden(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "model_reg = RegressionNN()\n",
        "dummy_input = torch.tensor([[0.5, 0.8]], dtype=torch.float32)\n",
        "prediction = model_reg(dummy_input)\n",
        "\n",
        "print(\"Model prediction for dummy input:\", prediction.item())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
